---
date: 2021-07-05 00:38
title: "NN basics - RNN"
categories: DevCourse2 NN DL MathJax RNN DevCourse2_NN_Basics
tags: DevCourse2 NN DL MathJax RNN DevCourse2_NN_Basics
## ëª©ì°¨
toc: true  
toc_sticky: true 
toc_label : "Contents"
---

# Sequential Data
## í‘œí˜„
- ë²¡í„°ì˜ ë²¡í„°
    - $$\boldsymbol{x} = (\boldsymbol{x}^{(1)}, \boldsymbol{x}^{(2)},\ldots ,\boldsymbol{x}^{(T)})^{T}$$.
- ì‚¬ì „
    - BoW
        - ë¹ˆë„ìˆ˜ë¥¼ ì„¸ì„œ $$m$$ì°¨ì›ì˜ ë²¡í„°ë¡œ í‘œí˜„ ($$m$$ì€ ì‚¬ì „ í¬ê¸°)
        - ì •ë³´ ê²€ìƒ‰ì— ì£¼ë¡œ ì‚¬ìš©.
        - MLì— ë¶€ì ì ˆ
        - ì‹œê°„ì •ë³´ê°€ ì‚¬ë¼ì§
    - One hot Encoding
        - í•œ ë‹¨ì–´ë¥¼ í‘œí˜„í•˜ëŠ”ë° mì°¨ì› ë²¡í„° ì‚¬ìš©
        - ë¹„íš¨ìœ¨
        - ë‹¨ì–´ê°„ ìœ ì‚¬ì„± ì¸¡ì • ë¶ˆê°€
        - $$\boldsymbol{x}^{(1)} = ((0,0,0,1,0,\ldots)^{T}, (1,0,0,,0,\ldots)^{T}, \ldots)^{T}$$.
    - word embedding
        - w2v
        - ë‹¨ì–´ ì‚¬ì´ì˜ ìƒí˜¸ì‘ìš©ì„ ë¶„ì„í•˜ì—¬ ìƒˆë¡œìš´ ê³µê°„ìœ¼ë¡œ ë³€í™˜( ë³´í†µ më³´ë‹¤ í›¨ì”¬ ë‚®ì€ ì°¨ì›ìœ¼ë¡œ ë³€í™˜)

## íŠ¹ì„±
- ìˆœì„œê°€ ì¤‘ìš”í•¨
- ìƒ˜í”Œë§ˆë‹¤ ë‹¤ë¥¸ ê¸¸ì´
- ë¬¸ë§¥ ì˜ì¡´ì„±
    - ê³µë¶„ì‚°ì€ ì˜ë¯¸ì—†ê³  ë¬¸ë§¥ ì˜ì¡´ì„±ì´ ì¤‘ìš”í•¨
    - ì¥ê¸° ì˜ì¡´ì„±ì€ LSTMìœ¼ë¡œ ì²˜ë¦¬ê°€ëŠ¥í•¨.

# RNN
- ì‹œê°„ì„±
    - ìˆœì„œ
- ê°€ë³€ê¸¸ì´
- ë¬¸ë§¥ ì˜ì¡´ì„±
    - ì´ì „ íŠ¹ì§•ì„ ê¸°ì–µí•´ì•¼í•¨  

## êµ¬ì¡°
- ì…ë ¥ì¸µ, ì€ë‹‰ì¸µ, ì¶œë ¥ì¸µ
- ì€ë‹‰ì¸µì´ recurrent edgeë¥¼ ê°–ìŒ.
    - ì‹œê°„ì„±, ê°€ë³€ê¸¸ì´, ë¬¸ë§¥ ì˜ì¡´ì„±ì„ ëª¨ë‘ ì²˜ë¦¬
    - **recurrent edge**ëŠ” $$t-1$$ì— ë°œìƒí•œ ì •ë³´ë¥¼ $$t$$ë¡œ ì „ë‹¬í•˜ëŠ” ì—­í• 
### ìˆ˜ì‹
$$\boldsymbol{h}^{(t)} = f(\boldsymbol{h}^{(t-1)}, \boldsymbol{x}^{(t)};\theta)$$
$$\theta$$ëŠ” ì‹ ê²½ë§ì˜ ë§¤ê°œë³€ìˆ˜
![rnn-structure-1](/assets/images/rnn-structure-1.png){: .align-center}  
![rnn-formula](/assets/images/rnn-formula.png){: .align-center}  


### ë§¤ê°œë³€ìˆ˜
- ìˆœí™˜ ì‹ ê²½ë§ì˜ ë§¤ê°œë³€ìˆ˜(ê°€ì¤‘ì¹˜ ì§‘í•©)ëŠ” $$\theta = \left\{ \boldsymbol{U}, \boldsymbol{W}, \boldsymbol{V}, \boldsymbol{b}, \boldsymbol{c}  \right\}$$
- $$\boldsymbol{U}$$: ì…ë ¥ì¸µê³¼ ì€ë‹‰ì¸µì„ ì—°ê²°í•˜ëŠ” $$p*d$$ í–‰ë ¬
- $$\boldsymbol{W}$$: ì€ë‹‰ì¸µê³¼ ì€ë‹‰ì¸µì„ ì—°ê²°í•˜ëŠ” $$p*p$$ í–‰ë ¬
- $$\boldsymbol{V}$$: ì€ë‹‰ì¸µê³¼ ì¶œë ¥ì¸µì„ ì—°ê²°í•˜ëŠ” $$q*p$$ í–‰ë ¬
- $$\boldsymbol{b}, \boldsymbol{c}$$: ë°”ì´ì–´ìŠ¤ë¡œì„œ ê°ê° $$p*1$$ê³¼ $$q*1$$ í–‰ë ¬  

ğŸ‘‰ RNN í•™ìŠµì´ë€ í›ˆë ¨ì§‘í•©ì„ ìµœì ì˜ ì„±ëŠ¥ìœ¼ë¡œ ì˜ˆì¸¡í•˜ëŠ” $$\theta$$ ê°’ì„ ì°¾ëŠ” ì¼  

#### Re-use the same weight matrix at every time-step  
![rnn-structure-2](/assets/images/rnn-structure-2.png){: .align-center}  

#### Example: Character-levelLanguage Model
![char-level-lang-model-ex-1](/assets/images/char-level-lang-model-ex-1.png){: .align-center}  
  

### ë³€í˜•
![rnn-structure-types](/assets/images/rnn-structure-types.png){: .align-center}  

#### Sequence to Sequence
![seq-2-seq](/assets/images/seq-2-seq.png){: .align-center}  
- Transformer êµ¬ì¡°
    - Encoder and Decoder  


## ë™ì‘
### ê°€ì¤‘ì¹˜
$$\boldsymbol{U}_{j} = ( u_{j1}, u_{j2}, \ldots, u_{jd} )$$ ëŠ” $$\boldsymbol{U}$$ í–‰ë ¬ì˜ $$j$$ë²ˆì§¸ í–‰($$h_j$$ì— ì—°ê²°ëœ ì„ ì˜ ê°€ì¤‘ì¹˜ë“¤)  

### ì€ë‹‰ì¸µ
$$h_j^{(t)} = \tau(a_{j}^{t})$$, $$j = 1,\ldots,p$$  
ì´ ë•Œ $$a_j^{(t)} = \boldsymbol{w}_{j}\boldsymbol{h}^{(t-1)} + \boldsymbol{u}_{j}\boldsymbol{x}^{(t)} + \boldsymbol{b}_{j}$$.  
![rnn-hidden](/assets/images/rnn-hidden.png){: .align-center .img-40}  

$$\boldsymbol{w}_{j}\boldsymbol{h}^{(t-1)}$$ì„ ì œì™¸í•˜ë©´ MLPì™€ ë™ì¼.

í–‰ë ¬ í‘œê¸°ë¡œ ì“°ë©´,  

$$h^{(t)} = \tau(a^{t})$$, $$\boldsymbol{a}^{(t)} = \boldsymbol{W}\boldsymbol{h}^{(t-1)} + \boldsymbol{U}\boldsymbol{x}^{(t)} + \boldsymbol{b}$$  

### ì¶œë ¥ì¸µ
$$\boldsymbol{o}^{(t)} = \boldsymbol{V}\boldsymbol{h}^{(t)} + \boldsymbol{c}$$.  
$$\boldsymbol{y}^{\prime(t)} = softmax(\boldsymbol{o}^{(t)})$$.  
![rnn-hidden-output](/assets/images/rnn-hidden-output.png){: .align-center .img-40}  

### ê³„ì‚° ì˜ˆì œ
![rnn-calculation-example](/assets/images/rnn-calculation-example.png){: .align-center}  


### ê¸°ì–µê³¼ ë¬¸ë§¥ ì˜ì¡´ì„± ê¸°ëŠ¥

## BPTT í•™ìŠµ (Backpropagation Through Time)
### DMLPì™€ ìœ ì‚¬ì„±
- ë‘˜ë‹¤ ì…ë ¥ì¸µ, ì€ë‹‰ì¸µ, ì¶œë ¥ì¸µì„ ê°€ì§.
### DMLPì™€ ì°¨ë³„ì„±
- RNNì€ ìƒ˜í”Œë§ˆë‹¤ ì€ë‹‰ì¸µì˜ ìˆ˜ê°€ ë‹¤ë¦„
- DMLPëŠ” ì™¼ìª½ì— ì…ë ¥, ì˜¤ë¥¸ìª½ì— ì¶œë ¥ì´ ìˆì§€ë§Œ, RNNì€ ë§¤ ìˆœê°„ ì…ë ¥ê³¼ ì¶œë ¥ì´ ìˆìŒ
- RNNì€ ê°€ì¤‘ì¹˜ë¥¼ ê³µìœ í•¨
    - DMLPëŠ” ê°€ì¤‘ì¹˜ë¥¼ $$ğ–^1,ğ–^ğŸ, ğ–^ğŸ‘,â‹¯$$ë¡œ í‘œê¸°í•˜ëŠ”ë°, RNNì€ ğ–ë¡œ í‘œê¸°

### ëª©ì í•¨ìˆ˜ ì •ì˜
- MSE, CrossEntropy, NLL  

### Gradient ê³„ì‚°
$$\frac{\partial j}{\partial \theta}$$ ë¥¼ êµ¬í•˜ë ¤ë©´, $$\theta = \left\{ \boldsymbol{U}, \boldsymbol{W}, \boldsymbol{V}, \boldsymbol{b}, \boldsymbol{c}  \right\}$$ì´ë¯€ë¡œ $$\frac{\partial j}{\partial ğ”},\frac{\partial j}{\partial ğ–}, \frac{\partial j}{\partial ğ•},  \frac{\partial j}{\partial ğ›},  \frac{\partial j}{\partial ğœ}$$ ë¥¼ ê³„ì‚°í•´ì•¼ í•¨.  
$$\boldsymbol{V}$$ëŠ” ì¶œë ¥ì—ë§Œ ì˜í–¥ì„ ë¯¸ì¹˜ë¯€ë¡œ $$\frac{\partial j}{\partial ğ•}$$ ê³„ì‚°ì´ ê°€ì¥ ê°„ë‹¨í•¨.  

$$\frac{\partial j}{\partial ğ•}$$ëŠ” $$q*p$$ í–‰ë ¬

![rnn-v-equation](/assets/images/rnn-v-equation.png){: .align-center}  

### BPTT ì•Œê³ ë¦¬ì¦˜
![bptt-equation](/assets/images/bptt-equation.png){: .align-center}  
$$ğ‘£_ğ‘—ğ‘–$$ë¡œ ë¯¸ë¶„í•˜ëŠ” ìœ„ì˜ ì‹ì„ í–‰ë ¬ ì „ì²´ë¥¼ ìœ„í•œ ì‹ $$\frac{\partial j}{\partial ğ•}$$ë¡œ í™•ì¥í•˜ê³ , $$\frac{\partial j}{\partial ğ”},\frac{\partial j}{\partial ğ–}, \frac{\partial j}{\partial ğ•},  \frac{\partial j}{\partial ğ›},  \frac{\partial j}{\partial ğœ}$$  ê¹Œì§€ ìœ ë„í•˜ë©´ BPTTê°€ ì™„ì„±ë¨  

$$\frac{\partial J^{(t)}}{\partial \boldsymbol{O}^{(t)}} = \boldsymbol{y}^{\prime(t)} - \boldsymbol{y}^{(t)}$$  

### ì€ë‹‰ì¸µ ë¯¸ë¶„
ìˆœê°„ $$t$$ì˜ ì€ë‹‰ì¸µ ê°’ $$\boldsymbol{h}^{(t)}$$ì˜ ë¯¸ë¶„ì€ ê·¸ ì´í›„ì˜ ì€ë‹‰ì¸µê³¼ ì¶œë ¥ì¸µì— ì˜í–¥ì„ ì£¼ë¯€ë¡œ $$\boldsymbol{v}$$ë¡œ ë¯¸ë¶„í•˜ëŠ” ê²ƒë³´ë‹¤ ë³µì¡.  

- ë§ˆì§€ë§‰ ìˆœê°„ $$T$$ì— ëŒ€í•´ ë¯¸ë¶„ì‹ì„ ìœ ë„í•˜ë©´,  
    - $$\frac{\partial J^{(T)}}{\partial \boldsymbol{h}^{(T)}} = \frac{\partial j^{(t)}}{\partial \boldsymbol{o}^{(T)}}\frac{\partial \boldsymbol{o}^{(T)}}{\partial \boldsymbol{h}^{(T)}} = \boldsymbol{V}^{T}\frac{\partial J^{(T)}}{\partial \boldsymbol{o}^{(T)}}$$.  
    - $$\boldsymbol{o}^{(t)} = \boldsymbol{V}\boldsymbol{h}^{t} + \boldsymbol{c}$$.  
- T-1 ìˆœê°„ì˜ ê·¸ë ˆì´ë””ì–¸íŠ¸ë¥¼ ìœ ë„í•˜ë©´
    - $$ğƒ(1âˆ’(ğ¡^((ğ‘‡)) )^2 )$$ëŠ” $$ğ‘–$$ë²ˆ ì—´ì˜ ëŒ€ê°ì„ ì´ $$1âˆ’(â„_ğ‘–^((ğ‘‡)) )^2$$ì„ ê°€ì§„ ëŒ€ê° í–‰ë ¬
    - ![t-1-gradient](/assets/images/t-1-gradient.png){: .align-center}  
- t ìˆœê°„ìœ¼ë¡œ ì¼ë°˜í™”í•˜ë©´
    - $$ğ½^(\tilde t)$$ëŠ” të¥¼ í¬í•¨í•˜ì—¬ ì´í›„ì˜ ëª©ì í•¨ìˆ«ê°’ì„ ëª¨ë‘ ë”í•œ ê°’, ì¦‰ $$ğ½^(\tilde t)=ğ½^((ğ‘¡))+ğ½^((ğ‘¡+1))+â‹¯+ğ½^((ğ‘‡))$$.  
    - ![t-gradient](/assets/images/t-gradient.png){: .align-center}  
- ![bptt-gradient](/assets/images/bptt-gradient.png){: .align-center}  

## ì–‘ë°©í–¥ RNN
### ì–‘ë°©í–¥ ë¬¸ë§¥ ì˜ì¡´ì„±
ì™¼ìª½ì—ì„œ ì˜¤ë¥¸ìª½ìœ¼ë¡œë§Œ ì •ë³´ê°€ íë¥´ëŠ” ë‹¨ë°©í–¥ RNNì˜ í•œê³„
### ì–‘ë°©í–¥ RNN (Bidirectional RNN)
tìˆœê°„ì˜ ë‹¨ì–´ëŠ” ì•ë’¤ ë‹¨ì–´ ì •ë³´ë¥¼ ëª¨ë‘ ë³´ê³  ì²˜ë¦¬.

## ì¥ê¸° ë¬¸ë§¥ ì˜ì¡´ì„±
ê´€ë ¨ëœ ìš”ì†Œê°€ ë©€ì´ ë–¨ì–´ì§„ ìƒí™©

![rnn-vanishing-gradient.jpg](/assets/images/rnn-vanishing-gradient.jpg){: .align-center .img-50}  

- ë¬¸ì œì 
    - gradient vanishing
    - gradient explosion
    - RNNì€ CNNë³´ë‹¤ ì‹¬í•¨
        - ê¸´ ìƒ˜í”Œì´ ìì£¼ ìˆê¸° ë•Œë¬¸.
        - ê°€ì¤‘ì¹˜ ê³µìœ  ë•Œë¬¸ì— ê°™ì€ ê°’ì„ ê³„ì† ê³±í•¨.  

LSTM ì´ í•´ê²°ì±…  

## LSTM (Long short term memory)
### Gate
- ì…ë ¥ ê²Œì´íŠ¸ì™€ ì¶œë ¥ ê²Œì´íŠ¸
    - ê²Œì´íŠ¸ë¥¼ ì—´ë©´(â­•) ì‹ í˜¸ê°€ íë¥´ê³ , ë‹«ìœ¼ë©´(ğŸš«) ì°¨ë‹¨ë¨
    - ì˜ˆ, [ê·¸ë¦¼ 8-14]ì—ì„œ t=1ì—ì„œëŠ” ì…ë ¥ë§Œ ì—´ë ¸ê³ , 32ì™€ 33ì—ì„œëŠ” ì…ë ¥ê³¼ ì¶œë ¥ì´ ëª¨ë‘ ì—´ë¦¼
    - ì‹¤ì œë¡œëŠ” [0,1] ì‚¬ì´ì˜ ì‹¤ìˆ«ê°’ìœ¼ë¡œ ê°œí ì •ë„ë¥¼ ì¡°ì ˆ
    - ì´ ê°’ì€ í•™ìŠµìœ¼ë¡œ ì•Œì•„ëƒ„
    - ![gate-open-close](/assets/images/gate-open-close.png){: .align-center}  

### LSTM GATES
- ë©”ëª¨ë¦¬ ë¸”ë¡(ì…€): ì€ë‹‰ ìƒíƒœ(hidden state) ì¥ê¸°ê¸°ì–µ
- ë§ê°(forget) gate: ê¸°ì–µ ìœ ì§€ í˜¹ì€ ì œê±° (1: ìœ ì§€, 0: ì œê±°)
- ì…ë ¥(input) gate: ì…ë ¥ ì—°ì‚°
- ì¶œë ¥(output) gate: ì¶œë ¥ ì—°ì‚°  

<!-- ![lstm-figure](/assets/images/lstm-figure.png){: .align-center}   -->
![/assets/images/lstm-gates-figure.png](/assets/images/lstm-gates-figure.png){: .align-center}  

```md
- i: Input gate, whether to write to cell
- f: Forget gate, Whether to erase cell
- o: Output gate, How much to reveal cell
- g: Gate gate(?), How much to write to cell
```

- $$c_tâ€‹$$: ê³¼ê±°ë¡œë¶€í„° ì‹œê° tê¹Œì§€ì˜ ëª¨ë“  ì •ë³´ ì €ì¥. ê¸°ì–µ ì…€. 
- $$h_t$$: ê¸°ì–µì…€ $$c_t$$ë¥¼ tanh í•¨ìˆ˜ ì ìš© 
- o: output ê²Œì´íŠ¸. ë‹¤ìŒ ì€ì‹ ìƒíƒœ $$h_t$$ì‚°ì¶œ. ì…ë ¥ $$x_t, h_{t-1}$$ì„ ë°›ìŒ. 
    - formula: $$o = \sigma(x_t W_{xo} + h_{t-1} W_{ho}+b_o)$$ 
    - return: $$h_t = o \odot tanh(c_t)â€‹$$ 
- f: forget ê²Œì´íŠ¸. ê¸°ì–µì…€ $$c_t$$ ì‚°ì¶œ. $$x_t, h_{t-1}â€‹$$ì„ ë°›ìŒ. 
    - formula: $$f = \sigma(x_t W_{xf} + h_{t-1} W_{hf} + b_f)$$ 
    - return: $$c_t = f \odot c_{t-1}â€‹$$ 
- g: tanh ë…¸ë“œ. ìƒˆë¡œ ê¸°ì–µí•´ì•¼ í•  ì •ë³´ë¥¼ â€˜ê¸°ì–µì…€â€™ì— ì¶”ê°€. &rArr; ìœ„ ê·¸ë¦¼ì—ì„œ $$\tilde{c}_t$$ 
    - formula: $$g = tanh(x_t W_{xg} + h_{t-1} W_{hg} + b_g)â€‹$$ 
- i: input ê²Œì´íŠ¸. ìƒˆë¡œ ê¸°ì–µí•´ì•¼ í•  ì •ë³´(gì˜ ê²°ê³¼ë¬¼)ì˜ ì¤‘ìš”ë„ íŒë³„=ê°€ì¤‘ì¹˜. 
    - formula: $$i = \sigma(x_t W_{xi} + h_{t-1} W_{hi} + b_i)$$ 
- params ì •ë¦¬
    - $$f = \sigma(x_t W_{xf} + h_{t-1} W_{hf} + b_f)$$.
    - $$g = tanh(x_t W_{xg} + h_{t-1} W_{hg} + b_g)$$.
    - $$i = \sigma(x_t W_{xi} + h_{t-1} W_{hi} + b_i)$$.
    - $$o = \sigma(x_t W_{xo} + h_{t-1} W_{ho}+b_o)$$.
    - $$c_t = f \odot c_{t-1}$$.
    - $$h_t = o \odot tanh(c_t)â€‹$$.

#### RNNê³¼ LSTMì˜ ë¹„êµ
LSTMì€ ë©”ëª¨ë¦¬ ì…€ì„ ê°€ì§.  

### LSTM ê°€ì¤‘ì¹˜
- ì…ë ¥ë‹¨ê³¼ ì—°ê²°í•˜ëŠ” $$ğ–^ğ‘”$$, ì…ë ¥ ê²Œì´íŠ¸ì™€ ì—°ê²°í•˜ëŠ” $$ğ–^ğ’Š$$, ì¶œë ¥ ê²Œì´íŠ¸ì™€ ì—°ê²°í•˜ëŠ” $$ğ–^ğ’$$
- ì…ë ¥ì¸µê³¼ ì€ë‹‰ì¸µì„ ì—°ê²°í•˜ëŠ” ê°€ì¤‘ì¹˜ $$ğ”$$  

![/assets/images/lstm-weights.png](/assets/images/lstm-weights.png){: .align-center}  

### ë§ê° ê²Œì´íŠ¸ì™€ í•í™€
![/assets/images/lstm-gates-block-figure.png](/assets/images/lstm-gates-block-figure.png){: .align-center}  

### LSTM ë™ì‘
Uninterrupted Gradient Flow!  

![/assets/images/lstm-gradient-flow.png](/assets/images/lstm-gradient-flow.png){: .align-center}  

- forget-gate
    - ![/assets/images/forget-gate.gif](/assets/images/forget-gate.gif){: .align-center .img-70}
- input-gate
    - ![/assets/images/input-gate.gif](/assets/images/input-gate.gif){: .align-center .img-70}
- cell-gate
    - ![/assets/images/cell-gate.gif](/assets/images/cell-gate.gif){: .align-center .img-70}
- output-gate
    - ![/assets/images/output-gate.gif](/assets/images/output-gate.gif){: .align-center .img-70}  


## ì‘ìš© ì‚¬ë¡€
### ì–¸ì–´ ëª¨ë¸
- ë¬¸ì¥, ì¦‰ ë‹¨ì–´ ì—´ì˜ í™•ë¥ ë¶„í¬ë¥¼ ëª¨í˜•í™”
- ìŒì„± ì¸ì‹ê¸° ë˜ëŠ” ì–¸ì–´ ë²ˆì—­ê¸°ê°€ í›„ë³´ë¡œ ì¶œë ¥í•œ ë¬¸ì¥ì´ ì—¬ëŸ¬ ìˆì„ ë•Œ, ì–¸ì–´ ëª¨ë¸ë¡œ í™•ë¥ ì„ ê³„ì‚°í•œ ë‹¤ìŒ í™•ë¥ ì´ ê°€ì¥ ë†’ì€ ê²ƒì„ ì„ íƒí•´ì„œ ì„±ëŠ¥ì„ ë†’ì„.
- í™•ë¥ ë¶„í¬ë¥¼ ì¶”ì •í•˜ëŠ” ë°©ë²•
    - n-gram
        - joint probability
        - nì„ ì‘ê²Œ í•´ì•¼í•¨.
        - í™•ë¥  ì¶”ì •ì€ corpus ì‚¬ìš©
        - ë‹¨ì–´ê°€ oheë¡œ í‘œí˜„ë˜ë¯€ë¡œ ë‹¨ì–´ê°„ ê±°ë¦¬ ë°˜ì˜ ëª»í•¨.
    - mlp
    - rnn
        - í™•ë¥ ë¶„í¬ ì¶”ì •ë¿ë§Œ ì•„ë‹ˆë¼ ë¬¸ì¥ ìƒì„± ê¸°ëŠ¥ê¹Œì§€ ê°–ì¶¤
        - ë¹„ì§€ë„ í•™ìŠµì— í•´ë‹¹í•˜ì—¬ ë§ë­‰ì¹˜ë¡œë¶€í„° ì‰½ê²Œ í›ˆë ¨ì§‘í•© êµ¬ì¶•ê°€ëŠ¥
- ìˆœí™˜ ì‹ ê²½ë§ì˜ í•™ìŠµ
    - ë§ë­‰ì¹˜ì— ìˆëŠ” ë¬¸ì¥ì„ ë³€í™˜í•˜ì—¬ í›ˆë ¨ì§‘í•© ìƒì„±í›„ BPTT ì•Œê³ ë¦¬ì¦˜ ì ìš©
- ì¼ë°˜ì ìœ¼ë¡œ, ì‚¬ì „í•™ìŠµì„ ìˆ˜í–‰í•œ ì–¸ì–´ëª¨ë¸ì„ ê°œë³„ ê³¼ì œì— ë§ê²Œ ë¯¸ì„¸ ì¡°ì •í•¨
- ì£¼ìš” ì–¸ì–´ëª¨ë¸
    - ElMo
    - GPT
    - BERT  

### ê¸°ê³„ ë²ˆì—­
- ì–¸ì–´ëª¨ë¸ë³´ë‹¤ ì–´ë ¤ì›€
    - ì–¸ì–´ ëª¨ë¸ì€ ì…ë ¥ ë¬¸ì¥ê³¼ ì¶œë ¥ ë¬¸ì¥ì˜ ê¸¸ì´ê°€ ê°™ì€ë°, ê¸°ê³„ ë²ˆì—­ì€ ê¸¸ì´ê°€ ì„œë¡œ ë‹¤ë¥¸ seq2seq ë¬¸ì œ
    - ì–´ìˆœì´ ë‹¤ë¦„.
- í˜„ì¬ DL ê¸°ë°˜ ê¸°ê³„ ë²ˆì—­ ë°©ë²•ì´ ì£¼ë¥˜
- LSTMì„ ì‚¬ìš©í•˜ì—¬ ë²ˆì—­ ê³¼ì • ìì²´ë¥¼ í†µì§¸ë¡œ í•™ìŠµ
    - LSTM 2ê°œë¥¼ ì‚¬ìš©(encoder, decoder)
    - ê°€ë³€ ê¸¸ì´ì˜ ë¬¸ì¥ì„ ê³ ì • ê¸¸ì´ì˜ íŠ¹ì§• ë²¡í„°ë¡œ ë³€í™˜í›„ ê°€ë³€ ê¸¸ì´ ë¬¸ì¥ ìƒì„±  
    - EncoderëŠ” $$\boldsymbol{x}$$ë¥¼ $$\boldsymbol{h}_Ts$$ë¼ëŠ” feature vectorë¡œ ë³€í™˜í›„ Decoderë¡œ $$\boldsymbol{h}_Ts$$ë¥¼ ê°€ì§€ê³  ë¬¸ì¥ ìƒì„±.
    - ![/assets/images/transformer.gif](/assets/images/transformer.gif){: .align-center}  
    

### ì˜ìƒ ì£¼ì„ ìƒì„±
- ì˜ìƒ ì† ë¬¼ì²´ë¥¼ ê²€ì¶œí•˜ê³  ì¸ì‹, ë¬¼ì²´ì˜ ì†ì„±ê³¼ í–‰ìœ„, ë¬¼ì²´ ê°„ì˜ ìƒí˜¸ì‘ìš©ì„ ì•Œì•„ë‚´ëŠ” ì¼
- CNN ìœ¼ë¡œ ì˜ìƒì„ ë¶„ì„í•˜ê³  ì¸ì‹ + LSTM ë¬¸ì¥ìƒì„±
- CNN: ì…ë ¥ ì˜ìƒì„ ë‹¨ì–´ ì„ë² ë”© ê³µê°„ì˜ íŠ¹ì§• ë²¡í„°ë¡œ ë³€í™˜
- ![/assets/images/img-captioning.png](/assets/images/img-captioning.png){: .align-center}
- ![/assets/images/Image-Captioning-with-Attention.png](/assets/images/Image-Captioning-with-Attention.png){: .align-center}



# Appendix
## Arrows
&rArr;, &rarr;  
```
&rArr; &rarr;
```

## Reference
{% include video id="4Bdc55j80l8" provider="youtube" %}  

> CNN cs231n lecture_10 RNN: <http://cs231n.stanford.edu/slides/2021/lecture_8.pdf>  
> LSTM: <https://github.com/llSourcell/LSTM_Networks/blob/master/LSTM%20Demo.ipynb>  
> LSTM illustrated guide: <https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21>  
> Transformer illustrated guide: <https://towardsdatascience.com/illustrated-guide-to-transformers-step-by-step-explanation-f74876522bc0>  
> Attention is All you need: <https://youtu.be/4Bdc55j80l8>  
> arrows: <https://www.w3schools.com/charsets/ref_utf_arrows.asp>  